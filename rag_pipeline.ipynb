{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ca4318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RAG PIPELINE — SINGLE CELL\n",
    "# =========================\n",
    "\n",
    "import warnings, time, re, urllib.parse, requests, numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List, Dict\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from huggingface_hub import InferenceClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c6492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG --------\n",
    "USER_AGENT = \"RAG-Notebook/0.1\"\n",
    "WIKI_REST_API = \"https://en.wikipedia.org/w/rest.php/v1\"\n",
    "WIKI_ACTION_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "TOPIC = \"How has artificial intelligence been used in military operations?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- HELPERS --------\n",
    "def clean_text(t): \n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "def session_with_retries(retries=3, backoff=1.5):\n",
    "    s = requests.Session()\n",
    "    s.headers.update({\"User-Agent\": USER_AGENT})\n",
    "    s.retries, s.backoff = retries, backoff\n",
    "    return s\n",
    "\n",
    "def get_json(session, url, params):\n",
    "    for i in range(session.retries):\n",
    "        try:\n",
    "            r = session.get(url, params=params, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except Exception:\n",
    "            time.sleep(session.backoff ** i)\n",
    "    raise RuntimeError(f\"Request failed: {url}\")\n",
    "\n",
    "def filter_near_duplicates(docs, embeddings, threshold=0.92):\n",
    "    vecs = np.array(embeddings.embed_documents([d.page_content for d in docs]))\n",
    "    keep, used = [], set()\n",
    "    for i in range(len(docs)):\n",
    "        if i in used:\n",
    "            continue\n",
    "        keep.append(i)\n",
    "        sims = (vecs @ vecs[i]) / (np.linalg.norm(vecs, axis=1) * np.linalg.norm(vecs[i]) + 1e-9)\n",
    "        used.update(np.where(sims >= threshold)[0])\n",
    "    return [docs[i] for i in keep]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a6a6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- WIKIPEDIA FETCH --------\n",
    "def wikipedia_fetch(topic, max_pages=6):\n",
    "    s = session_with_retries()\n",
    "    pages = get_json(\n",
    "        s, f\"{WIKI_REST_API}/search/page\", {\"q\": topic, \"limit\": max_pages}\n",
    "    ).get(\"pages\", [])\n",
    "\n",
    "    titles = [p[\"title\"] for p in pages]\n",
    "    extracts = get_json(\n",
    "        s, WIKI_ACTION_API,\n",
    "        {\n",
    "            \"action\": \"query\",\n",
    "            \"format\": \"json\",\n",
    "            \"prop\": \"extracts\",\n",
    "            \"explaintext\": \"1\",\n",
    "            \"titles\": \"|\".join(titles),\n",
    "        },\n",
    "    )[\"query\"][\"pages\"]\n",
    "\n",
    "    docs = []\n",
    "    for page in extracts.values():\n",
    "        text = clean_text(page.get(\"extract\", \"\"))\n",
    "        if len(text) < 300:\n",
    "            continue\n",
    "        title = page[\"title\"]\n",
    "        url = f\"https://en.wikipedia.org/wiki/{urllib.parse.quote(title.replace(' ', '_'))}\"\n",
    "        docs.append({\"title\": title, \"url\": url, \"text\": text})\n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7352bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- INGEST --------\n",
    "docs = wikipedia_fetch(TOPIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024a865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 1531.33it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "docs = [\n",
    "    d if hasattr(d, \"page_content\")\n",
    "    else Document(\n",
    "        page_content=d[\"text\"],\n",
    "        metadata={\"title\": d[\"title\"], \"source\": d[\"url\"]},\n",
    "    )\n",
    "    for d in docs\n",
    "]\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=900,\n",
    "    chunk_overlap=120,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"? \", \"! \", \"; \", \": \", \" \"],\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "chunks = filter_near_duplicates(chunks, embeddings)\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"industry_data\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "vectorstore.add_documents(chunks)\n",
    "vectorstore.persist()\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 4, \"fetch_k\": 50, \"lambda_mult\": 0.7},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90511f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------- GENERATION --------\n",
    "client = InferenceClient()\n",
    "\n",
    "def generate_answer(query, docs):\n",
    "    context = \"\\n\".join(d.page_content for d in docs)\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        temperature=0.2,\n",
    "        max_tokens=200,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer only using the context.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion:\\n{query}\"},\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ed1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tool(query: str):\n",
    "    return retriever.invoke(query)\n",
    "\n",
    "def answer_tool(query: str, docs=None):\n",
    "    context = \"\\n\".join(d.page_content for d in docs) if docs else \"\"\n",
    "    return generate_answer(query, docs or [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "729c7c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def needs_retrieval(query: str) -> bool:\n",
    "    decision_prompt = f\"\"\"\n",
    "Decide if the following question requires external knowledge.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer only YES or NO.\n",
    "\"\"\"\n",
    "    out = client.chat.completions.create(\n",
    "        model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        messages=[{\"role\": \"user\", \"content\": decision_prompt}],\n",
    "        max_tokens=5,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    return \"YES\" in out.choices[0].message.content.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "081cb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agentic_answer(query: str):\n",
    "    if needs_retrieval(query):\n",
    "        docs = retrieve_tool(query)\n",
    "        return generate_answer(query, docs)\n",
    "    else:\n",
    "        return generate_answer(query, [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da262c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence has been used in military operations in various countries, including Iraq, Syria, Israel, and Ukraine. Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------- RUN --------\n",
    "retrieved_docs = retriever.invoke(TOPIC)\n",
    "answer = generate_answer(TOPIC, retrieved_docs)\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18a4d26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI has been increasingly used in education in various ways. Some of the key applications include:\n",
      "\n",
      "1. **Personalized Learning**: AI-powered systems can analyze a student's learning style, pace, and abilities to provide customized learning experiences. This can help students learn more effectively and efficiently.\n",
      "\n",
      "2. **Intelligent Tutoring Systems**: AI-based systems can offer one-on-one support to students, providing real-time feedback and guidance on complex topics. These systems can also adapt to a student's learning needs and adjust the level of difficulty accordingly.\n",
      "\n",
      "3. **Automated Grading**: AI can help teachers with grading by automating the process of scoring assignments and exams. This can save teachers time and reduce the risk of human error.\n",
      "\n",
      "4. **Natural Language Processing (NLP)**: AI-powered NLP can help students improve their language skills by providing interactive language learning tools, such as chatbots and virtual language assistants.\n",
      "\n",
      "5. **Content Creation**: AI can assist in creating educational content, such as generating quizzes\n"
     ]
    }
   ],
   "source": [
    "print(agentic_answer(\"How has AI been used in education?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
